{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": [],
      "authorship_tag": "ABX9TyNoIQs39FfmksNZcHVz5fU2",
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/pcrii/Philo-Colab-Collection/blob/main/textgen-webui-gdrive.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "cellView": "form",
        "id": "DXuCpvhyqZuS"
      },
      "outputs": [],
      "source": [
        "#@title Install text-generation-webui\n",
        "#@markdown install to Gdrive to store models for future use \n",
        "import os\n",
        "save_to_google_drive = True #@param {type:\"boolean\"}\n",
        "install_gptq = True\n",
        "\n",
        "if save_to_google_drive:\n",
        "    import os\n",
        "    import shutil\n",
        "    from google.colab import drive\n",
        "    drive.mount('/content/drive')\n",
        "    base_folder = '/content/drive/MyDrive'\n",
        "    repo_dir = '/content/drive/MyDrive/text-generation-webui'\n",
        "    model_dir = '/content/drive/MyDrive/text-generation-webui/models'\n",
        "    gptq_dir = '/content/drive/MyDrive/text-generation-webui/repositories/GPTQ-for-LLaMa'\n",
        "    if os.path.exists(repo_dir):\n",
        "        %cd {repo_dir}\n",
        "        !git pull\n",
        "    else:\n",
        "        %cd /content/drive/MyDrive/\n",
        "        !git clone https://github.com/oobabooga/text-generation-webui\n",
        "\n",
        "else:\n",
        "    model_dir = '/content/text-generation-webui/models'\n",
        "    repo_dir = '/content/text-generation-webui'\n",
        "    !git clone https://github.com/oobabooga/text-generation-webui\n",
        "\n",
        "\n",
        "%cd /content/text-generation-webui\n",
        "!wget https://oobabooga.github.io/settings-colab.json -O settings-colab-template.json\n",
        "\n",
        "# Install requirements\n",
        "!pip install -r requirements.txt\n",
        "!pip install -r extensions/google_translate/requirements.txt\n",
        "!pip install -r extensions/silero_tts/requirements.txt\n",
        "print(f\"\\033[1;32;1m\\n --> If you see a warning about \\\"pydevd_plugins\\\", just ignore it and move on to Step 3. There is no need to restart the runtime.\\n\\033[0;37;0m\")\n",
        "\n",
        "if install_gptq:\n",
        "    if save_to_google_drive:\n",
        "        if os.path.exists(gptq_dir):\n",
        "            %cd {gptq_dir}\n",
        "            !git pull\n",
        "            !pip install -r requirements.txt\n",
        "            !python setup_cuda.py install\n",
        "\n",
        "        else:\n",
        "            !mkdir /content/drive/MyDrive/text-generation-webui/repositories\n",
        "            %cd /content/drive/MyDrive/text-generation-webui/repositories\n",
        "            !git clone https://github.com/oobabooga/GPTQ-for-LLaMa.git -b cuda\n",
        "            %cd GPTQ-for-LLaMa\n",
        "            !pip install -r requirements.txt\n",
        "            !python setup_cuda.py install\n",
        "    else:\n",
        "        %mkdir /content/text-generation-webui/repositories/\n",
        "        %cd /content/text-generation-webui/repositories/\n",
        "        !git clone https://github.com/oobabooga/GPTQ-for-LLaMa.git -b cuda\n",
        "        %cd GPTQ-for-LLaMa\n",
        "        !pip install -r requirements.txt\n",
        "        !python setup_cuda.py install\n"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "#@title Download\n",
        "#@markdown copy a model name from hugging face and paste here. org/model\n",
        "hflink = \"cerebras/Cerebras-GPT-6.7B\" #@param {type:\"string\"}\n",
        "%cd {repo_dir}\n",
        "!python download-model.py {hflink}\n",
        "#@markdown examples: <br> ozcur/alpaca-native-4bit <br> anon8231489123/gpt4-x-alpaca-13b-native-4bit-128g <br> <br> you can download LoRa's just rerun the cell with its huggingface info and the script should place it where it needs to be\n"
      ],
      "metadata": {
        "cellView": "form",
        "id": "raiZGArTqvkn"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "#@title Available To Run\n",
        "#@markdown this cell just lists directorys from your model folder <br> copy the name provided for the model you want for use in the the next cell\n",
        "print(model_dir)\n",
        "print(os.listdir(model_dir))"
      ],
      "metadata": {
        "cellView": "form",
        "id": "JdX7h08bthnP"
      },
      "execution_count": null,
      "outputs": []
    }
  ]
}